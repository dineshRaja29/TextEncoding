{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textEncodings.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "AKoSscvZlfPR",
        "gtkAMxGAljIq",
        "F9Eqvyl5lke7"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dineshRaja29/TextEncodings/blob/main/textEncodings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6jU6Y3qkkwU"
      },
      "source": [
        "\n",
        "\n",
        "#<font color = 'green'><b>INTRODUCTION\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will explore various ways to encode text (conversion of text into numeric vector/scaler) from classical to state of art approach. There are broadly four methods which are extensively used in ML/DL.\n",
        "\n"
      ],
      "metadata": {
        "id": "AI6GrBxzES08"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4JdGi_Ek3n5"
      },
      "source": [
        "- BoW using SkLearn + Sparse Matrices\n",
        "- TF-IDF using SkLearn\n",
        "- Word2Vec using Gensim\n",
        "- BERT using bert-serving library + APIs.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui-G-YK9lY1O"
      },
      "source": [
        "#<font color = 'green'><b>Data loading"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "import sys\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "gV3uXqRvFfan"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sys.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVP_uxxvGkR-",
        "outputId": "8ade85dd-d7a3-4321-9dc9-dd1a3bd0170d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7.13 (default, Apr 24 2022, 01:04:09) \n",
            "[GCC 7.5.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-requisted for stopword and word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZssqMwvF0A3",
        "outputId": "a316ce97-3b63-4b26-d730-1ca1a4b37c15"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-requisted for Lemmatize\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoKPJ8RSF7Ju",
        "outputId": "ee2b4f02-848d-42d5-ee26-69d85e0335b2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wULjRbeilXlX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ee11358-5447-475b-9a9f-fae116de9046"
      },
      "source": [
        "# Source: http://ai.stanford.edu/~amaas/data/sentiment/\n",
        "! wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-03 18:16:57--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  31.2MB/s    in 2.6s    \n",
            "\n",
            "2022-05-03 18:17:00 (31.2 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z12NKVwXMUMW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eb83dce-502d-4321-eb28-f81bd7bf81c8"
      },
      "source": [
        "# uncompress and see the data\n",
        "! ls\n",
        "! pwd"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aclImdb_v1.tar.gz  sample_data\t\t    uncased_L-12_H-768_A-12.zip\n",
            "out.file\t   uncased_L-12_H-768_A-12\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIBqDuFlOdot"
      },
      "source": [
        "! tar -zxvf aclImdb_v1.tar.gz >& /dev/null"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCO287B1C616",
        "outputId": "0b5db555-a72f-4471-a952-9fd5366abf01"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aclImdb\t\t   out.file\tuncased_L-12_H-768_A-12\n",
            "aclImdb_v1.tar.gz  sample_data\tuncased_L-12_H-768_A-12.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_OKW4ZKMoJO"
      },
      "source": [
        "#Google: \"Unzip tar gz file colab\" ----> https://stackoverflow.com/questions/49685924/extract-google-drive-zip-from-google-colab-notebook\n",
        "# shutil.unpack_archive(\"/content/aclImdb_v1.tar.gz\", \"/content/\")\n",
        "# ! ls /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YfL_UK1NRBh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5342331-0b13-4436-f39b-10bee0fd34f5"
      },
      "source": [
        "! ls -l /content/aclImdb"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1724\n",
            "-rw-r--r-- 1 7297 1000 903029 Jun 11  2011 imdbEr.txt\n",
            "-rw-r--r-- 1 7297 1000 845980 Apr 12  2011 imdb.vocab\n",
            "-rw-r--r-- 1 7297 1000   4037 Jun 26  2011 README\n",
            "drwxr-xr-x 4 7297 1000   4096 May  3 18:17 test\n",
            "drwxr-xr-x 5 7297 1000   4096 May  3 18:17 train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lJFHQLzNhpj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7ccb5db-d826-4303-a709-c3a26e65e391"
      },
      "source": [
        "! head -10 /content/aclImdb/imdb.vocab"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the\n",
            "and\n",
            "a\n",
            "of\n",
            "to\n",
            "is\n",
            "it\n",
            "in\n",
            "i\n",
            "this\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbE3Tr-tNqlT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d98cbca7-8338-4710-9042-2cfcc186d68d"
      },
      "source": [
        "! ls /content/aclImdb/train"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labeledBow.feat  pos\tunsupBow.feat  urls_pos.txt\n",
            "neg\t\t unsup\turls_neg.txt   urls_unsup.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZsjLhLqN6kx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2391bc4b-730d-488e-e3e9-2e4f9fb2b725"
      },
      "source": [
        "! ls /content/aclImdb/train/pos | head -10"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0_9.txt\n",
            "10000_8.txt\n",
            "10001_10.txt\n",
            "10002_7.txt\n",
            "10003_8.txt\n",
            "10004_8.txt\n",
            "10005_7.txt\n",
            "10006_7.txt\n",
            "10007_7.txt\n",
            "10008_7.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QscugZfCPTcV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6035cdb0-422f-4a9c-bc10-da0b98bf410f"
      },
      "source": [
        "! cat /content/aclImdb/train/pos/6250_10.txt | tr -s ' ' '\\n' | head -20 | tr -s '\\n' ' '"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There is something special about the Austrian movies not only by Seidl, but by Spielmann and other directors as well. "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGH_bManPY5D"
      },
      "source": [
        "# load data from k-reviews from imdb/train/pos reviews\n",
        "\n",
        "k=100\n",
        "\n",
        "raw_data = [] # empty list, \n",
        "\n",
        "\n",
        "index_file = dict(); # store mapping from index to filename\n",
        "\n",
        "directory = r'/content/aclImdb/train/pos/'\n",
        "\n",
        "i=0\n",
        "\n",
        "for f in os.listdir(directory): # for each file in the subfolder\n",
        "      \n",
        "  if f.endswith(\".txt\"): # check for text file\n",
        "    fname = directory + \"/\" + f\n",
        "    \n",
        "    tmp = open(fname, \"r\") # read file \n",
        "\n",
        "    raw_data.append(tmp.read())\n",
        "    index_file[i] = fname\n",
        "        \n",
        "    i += 1\n",
        "\n",
        "    if i==k: # read k files\n",
        "      break\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(i)\n",
        "print(index_file)\n",
        "print(raw_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fqm7gMLtFbCh",
        "outputId": "5a5f6181-f67d-4d7b-be2d-aa55c4fbbdb7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "{0: '/content/aclImdb/train/pos//11525_8.txt', 1: '/content/aclImdb/train/pos//8932_9.txt', 2: '/content/aclImdb/train/pos//8305_7.txt', 3: '/content/aclImdb/train/pos//11568_7.txt', 4: '/content/aclImdb/train/pos//10599_8.txt', 5: '/content/aclImdb/train/pos//11901_9.txt', 6: '/content/aclImdb/train/pos//343_10.txt', 7: '/content/aclImdb/train/pos//11378_8.txt', 8: '/content/aclImdb/train/pos//883_9.txt', 9: '/content/aclImdb/train/pos//10406_10.txt', 10: '/content/aclImdb/train/pos//11699_10.txt', 11: '/content/aclImdb/train/pos//3863_7.txt', 12: '/content/aclImdb/train/pos//11289_10.txt', 13: '/content/aclImdb/train/pos//10783_10.txt', 14: '/content/aclImdb/train/pos//5443_8.txt', 15: '/content/aclImdb/train/pos//3689_8.txt', 16: '/content/aclImdb/train/pos//11065_8.txt', 17: '/content/aclImdb/train/pos//6351_8.txt', 18: '/content/aclImdb/train/pos//9321_8.txt', 19: '/content/aclImdb/train/pos//672_9.txt', 20: '/content/aclImdb/train/pos//4989_8.txt', 21: '/content/aclImdb/train/pos//7496_8.txt', 22: '/content/aclImdb/train/pos//8349_10.txt', 23: '/content/aclImdb/train/pos//11013_7.txt', 24: '/content/aclImdb/train/pos//2046_8.txt', 25: '/content/aclImdb/train/pos//7067_7.txt', 26: '/content/aclImdb/train/pos//3836_8.txt', 27: '/content/aclImdb/train/pos//10514_8.txt', 28: '/content/aclImdb/train/pos//3878_10.txt', 29: '/content/aclImdb/train/pos//1636_10.txt', 30: '/content/aclImdb/train/pos//1628_10.txt', 31: '/content/aclImdb/train/pos//12479_10.txt', 32: '/content/aclImdb/train/pos//6535_10.txt', 33: '/content/aclImdb/train/pos//4650_7.txt', 34: '/content/aclImdb/train/pos//2266_8.txt', 35: '/content/aclImdb/train/pos//4087_10.txt', 36: '/content/aclImdb/train/pos//11083_10.txt', 37: '/content/aclImdb/train/pos//1212_8.txt', 38: '/content/aclImdb/train/pos//3246_9.txt', 39: '/content/aclImdb/train/pos//8293_8.txt', 40: '/content/aclImdb/train/pos//6727_9.txt', 41: '/content/aclImdb/train/pos//889_10.txt', 42: '/content/aclImdb/train/pos//2932_10.txt', 43: '/content/aclImdb/train/pos//7131_9.txt', 44: '/content/aclImdb/train/pos//2445_10.txt', 45: '/content/aclImdb/train/pos//2076_9.txt', 46: '/content/aclImdb/train/pos//5673_9.txt', 47: '/content/aclImdb/train/pos//6716_8.txt', 48: '/content/aclImdb/train/pos//8735_8.txt', 49: '/content/aclImdb/train/pos//7798_10.txt', 50: '/content/aclImdb/train/pos//5959_7.txt', 51: '/content/aclImdb/train/pos//9102_8.txt', 52: '/content/aclImdb/train/pos//8167_7.txt', 53: '/content/aclImdb/train/pos//11560_9.txt', 54: '/content/aclImdb/train/pos//7303_10.txt', 55: '/content/aclImdb/train/pos//8604_10.txt', 56: '/content/aclImdb/train/pos//4861_8.txt', 57: '/content/aclImdb/train/pos//2601_10.txt', 58: '/content/aclImdb/train/pos//7541_10.txt', 59: '/content/aclImdb/train/pos//2192_9.txt', 60: '/content/aclImdb/train/pos//11300_8.txt', 61: '/content/aclImdb/train/pos//3617_8.txt', 62: '/content/aclImdb/train/pos//10911_7.txt', 63: '/content/aclImdb/train/pos//12483_9.txt', 64: '/content/aclImdb/train/pos//2567_9.txt', 65: '/content/aclImdb/train/pos//10943_10.txt', 66: '/content/aclImdb/train/pos//6612_8.txt', 67: '/content/aclImdb/train/pos//11014_10.txt', 68: '/content/aclImdb/train/pos//8473_8.txt', 69: '/content/aclImdb/train/pos//9884_10.txt', 70: '/content/aclImdb/train/pos//5713_10.txt', 71: '/content/aclImdb/train/pos//5025_10.txt', 72: '/content/aclImdb/train/pos//4157_8.txt', 73: '/content/aclImdb/train/pos//3428_9.txt', 74: '/content/aclImdb/train/pos//10420_10.txt', 75: '/content/aclImdb/train/pos//2048_7.txt', 76: '/content/aclImdb/train/pos//7280_10.txt', 77: '/content/aclImdb/train/pos//2465_10.txt', 78: '/content/aclImdb/train/pos//2193_10.txt', 79: '/content/aclImdb/train/pos//12098_8.txt', 80: '/content/aclImdb/train/pos//8575_10.txt', 81: '/content/aclImdb/train/pos//4793_7.txt', 82: '/content/aclImdb/train/pos//8065_9.txt', 83: '/content/aclImdb/train/pos//5948_8.txt', 84: '/content/aclImdb/train/pos//1572_10.txt', 85: '/content/aclImdb/train/pos//8202_10.txt', 86: '/content/aclImdb/train/pos//7433_10.txt', 87: '/content/aclImdb/train/pos//1538_10.txt', 88: '/content/aclImdb/train/pos//11638_7.txt', 89: '/content/aclImdb/train/pos//8908_10.txt', 90: '/content/aclImdb/train/pos//1689_10.txt', 91: '/content/aclImdb/train/pos//6191_9.txt', 92: '/content/aclImdb/train/pos//1048_8.txt', 93: '/content/aclImdb/train/pos//1329_8.txt', 94: '/content/aclImdb/train/pos//2284_10.txt', 95: '/content/aclImdb/train/pos//3127_9.txt', 96: '/content/aclImdb/train/pos//9020_7.txt', 97: '/content/aclImdb/train/pos//4277_10.txt', 98: '/content/aclImdb/train/pos//6411_10.txt', 99: '/content/aclImdb/train/pos//2954_10.txt'}\n",
            "This movie is awesome for three main reasons. It is esthetically beautiful. I absolutely loved that. There is a bold color theme throughout the movie with extraordinary costumes and picturesque sets. A photography which looks very costly (and probably was not) completes the look . I always enjoy those stories about groups of misfits/loners coming together and becoming a family . Sometimes they fall into clichés but this one does not. This group of actors really portrays well flawed, yet extremely likable characters. Alan Larkin is the best (between him , the van and the road movie theme, I could not help but remember my favorite movie of last year Little Miss Sunshine) . I discovered Fabrizio Bentivoglio , very interesting actor, and just got annoyed a tiny little bit by Til Schweiger performance at times . The opening scene, all the scenes where they mess up their tricks are very funny. There is a mix of humor and emotion throughout the film. I like the end a lot. And of course it is all about the Magician theme . A good magician is making the audience look where he wants them to, to create an illusion. Which happens to be exactly what a movie director does and that's why they call it movie magic.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-evMcvglctN"
      },
      "source": [
        "##<font color = 'green'><b> Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not always removing stopword is helpful, 'not' is considered as a stopword\n",
        "for example:\n",
        "- He is bad boy\n",
        "- He is not a bad boy <br>\n",
        " After removal of stopword both makes the same sentences thus, harmful here <br>\n",
        "\n",
        " Another approach to fix this is to filter the list of stopwords based on language which you are working\n"
      ],
      "metadata": {
        "id": "C9YuhUfqLyMW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWKQIz0WoRkc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47ea9a73-b1fd-4781-c19d-61c506ccc424"
      },
      "source": [
        "\n",
        "example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
        "\n",
        "def stopWordRemoval(sent, stop_words):\n",
        "  word_tokens = word_tokenize(sent) # tokenize\n",
        "  filtered_sentence = \"\";\n",
        "  for w in word_tokens:\n",
        "      if w not in stop_words:\n",
        "          filtered_sentence += \" \" + w\n",
        "  return filtered_sentence\n",
        "\n",
        "stop_words = set(stopwords.words('english')) # NLTK \n",
        "print(stop_words)\n",
        "\n",
        "print(raw_data[0])\n",
        "print(stopWordRemoval(raw_data[0], stop_words) ) # call the function"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'before', 'our', 'just', 'their', 'me', 'you', 'him', 'all', 'how', 'whom', 'themselves', 'what', 'for', 'then', 'wouldn', 'where', 'your', 'them', 'if', 'that', 'very', \"hadn't\", 'we', 'does', 'both', 'been', 'no', 'is', 'any', 'shouldn', 'during', 'which', 'these', 'the', 'do', \"weren't\", 'but', 'after', 'with', 'few', 'a', 'below', \"you'll\", 'should', 'again', 'myself', 'when', 't', 'such', 'hers', 'her', 'too', \"you've\", 'most', 'by', 'further', 'through', 'off', 'had', 're', 'being', 'be', 'each', 'under', 'ma', 'couldn', 'not', \"you'd\", 'doesn', 'i', 'as', \"needn't\", \"don't\", 'shan', 'while', 'o', 'doing', \"doesn't\", 'they', 'have', 'out', \"it's\", 'why', 'aren', 'she', 'my', 'and', 'to', \"should've\", 'll', 'wasn', \"mustn't\", \"couldn't\", \"you're\", \"wouldn't\", 'between', 'has', 'his', 'now', 'there', \"won't\", 'was', 'are', 'who', 'or', 'at', 'yours', 'than', 'some', 'weren', 'because', 'here', 'y', 'about', 's', \"mightn't\", 'herself', \"wasn't\", 'yourself', 'its', 'having', 'mustn', \"didn't\", 'it', \"shouldn't\", 'in', 'will', 'hadn', 'hasn', 'itself', 'haven', 'down', \"that'll\", 'can', 'into', 'theirs', 'won', 'were', 'against', 'other', 'only', \"aren't\", \"haven't\", 'an', 'on', 'd', 'nor', 'same', 'up', 'did', 'yourselves', 'ourselves', 'he', 'own', 'this', 'didn', 'himself', 'am', \"isn't\", 'above', 'until', 'over', 'ain', 'don', 'those', 'from', 'needn', 'so', 'm', 'mightn', 'of', 've', 'isn', \"she's\", 'once', 'ours', \"shan't\", \"hasn't\", 'more'}\n",
            "This movie is awesome for three main reasons. It is esthetically beautiful. I absolutely loved that. There is a bold color theme throughout the movie with extraordinary costumes and picturesque sets. A photography which looks very costly (and probably was not) completes the look . I always enjoy those stories about groups of misfits/loners coming together and becoming a family . Sometimes they fall into clichés but this one does not. This group of actors really portrays well flawed, yet extremely likable characters. Alan Larkin is the best (between him , the van and the road movie theme, I could not help but remember my favorite movie of last year Little Miss Sunshine) . I discovered Fabrizio Bentivoglio , very interesting actor, and just got annoyed a tiny little bit by Til Schweiger performance at times . The opening scene, all the scenes where they mess up their tricks are very funny. There is a mix of humor and emotion throughout the film. I like the end a lot. And of course it is all about the Magician theme . A good magician is making the audience look where he wants them to, to create an illusion. Which happens to be exactly what a movie director does and that's why they call it movie magic.\n",
            " This movie awesome three main reasons . It esthetically beautiful . I absolutely loved . There bold color theme throughout movie extraordinary costumes picturesque sets . A photography looks costly ( probably ) completes look . I always enjoy stories groups misfits/loners coming together becoming family . Sometimes fall clichés one . This group actors really portrays well flawed , yet extremely likable characters . Alan Larkin best ( , van road movie theme , I could help remember favorite movie last year Little Miss Sunshine ) . I discovered Fabrizio Bentivoglio , interesting actor , got annoyed tiny little bit Til Schweiger performance times . The opening scene , scenes mess tricks funny . There mix humor emotion throughout film . I like end lot . And course Magician theme . A good magician making audience look wants , create illusion . Which happens exactly movie director 's call movie magic .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYb58jekoqxH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44525fc4-ec98-4185-a719-c1025b300757"
      },
      "source": [
        "# Lemmatize\n",
        "# Source: https://pythonprogramming.net/lemmatizing-nltk-tutorial/\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "print(lemmatizer.lemmatize(\"cats\"))\n",
        "print(lemmatizer.lemmatize(\"cacti\"))\n",
        "print(lemmatizer.lemmatize(\"geese\"))\n",
        "print(lemmatizer.lemmatize(\"rocks\"))\n",
        "print(lemmatizer.lemmatize(\"python\"))\n",
        "print(lemmatizer.lemmatize(\"better\", pos=\"a\"))\n",
        "print(lemmatizer.lemmatize(\"best\", pos=\"a\"))\n",
        "print(lemmatizer.lemmatize(\"run\"))\n",
        "print(lemmatizer.lemmatize(\"run\",'v'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat\n",
            "cactus\n",
            "goose\n",
            "rock\n",
            "python\n",
            "good\n",
            "best\n",
            "run\n",
            "run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gCe-Izeo0sa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64ad108f-b75d-4391-cc20-48b7c093ba27"
      },
      "source": [
        "\n",
        "example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
        "def stopWord_Lemmatize(sent, stop_words, lemmatizer ):\n",
        "  word_tokens = word_tokenize(sent) # tokenize\n",
        "  return_sent = \"\";\n",
        "  \n",
        "  for w in word_tokens:\n",
        "      if w not in stop_words:\n",
        "          return_sent +=  \" \" + lemmatizer.lemmatize(w) # lemmatize w before adding it to the return_sent\n",
        "  return return_sent\n",
        "\n",
        "stop_words = set(stopwords.words('english')) # NLTK \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "print(raw_data[0])\n",
        "print(stopWord_Lemmatize(raw_data[0], stop_words, lemmatizer) ) # call the function\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This movie is awesome for three main reasons. It is esthetically beautiful. I absolutely loved that. There is a bold color theme throughout the movie with extraordinary costumes and picturesque sets. A photography which looks very costly (and probably was not) completes the look . I always enjoy those stories about groups of misfits/loners coming together and becoming a family . Sometimes they fall into clichés but this one does not. This group of actors really portrays well flawed, yet extremely likable characters. Alan Larkin is the best (between him , the van and the road movie theme, I could not help but remember my favorite movie of last year Little Miss Sunshine) . I discovered Fabrizio Bentivoglio , very interesting actor, and just got annoyed a tiny little bit by Til Schweiger performance at times . The opening scene, all the scenes where they mess up their tricks are very funny. There is a mix of humor and emotion throughout the film. I like the end a lot. And of course it is all about the Magician theme . A good magician is making the audience look where he wants them to, to create an illusion. Which happens to be exactly what a movie director does and that's why they call it movie magic.\n",
            " This movie awesome three main reason . It esthetically beautiful . I absolutely loved . There bold color theme throughout movie extraordinary costume picturesque set . A photography look costly ( probably ) completes look . I always enjoy story group misfits/loners coming together becoming family . Sometimes fall clichés one . This group actor really portrays well flawed , yet extremely likable character . Alan Larkin best ( , van road movie theme , I could help remember favorite movie last year Little Miss Sunshine ) . I discovered Fabrizio Bentivoglio , interesting actor , got annoyed tiny little bit Til Schweiger performance time . The opening scene , scene mess trick funny . There mix humor emotion throughout film . I like end lot . And course Magician theme . A good magician making audience look want , create illusion . Which happens exactly movie director 's call movie magic .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THMiq2tppwGb"
      },
      "source": [
        "\n",
        "# pre-process the k sentences and store the result\n",
        "processed_data = []\n",
        "\n",
        "for sent in raw_data:\n",
        "  processed_data.append(stopWord_Lemmatize(sent, stop_words, lemmatizer) )"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKoSscvZlfPR"
      },
      "source": [
        "#<font color = 'green'><b>Bag-of-words (BoW)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mKbaEcsliiF"
      },
      "source": [
        "# Google \"sklearn bag of words\" ---> https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer() #https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
        "X_BoW = count_vect.fit_transform(processed_data)\n",
        "\n",
        "#print(count_vect.get_feature_names()) "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv-yEkW9rKI4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cadd16ac-ee98-45b4-b294-e99eb91a3ade"
      },
      "source": [
        "print(type(X_BoW))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse.csr.csr_matrix'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOSNhsyMrSin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0427080d-775b-426f-d0df-d54d93aada39"
      },
      "source": [
        "# Sparse representations vs dense Matrices\n",
        "\n",
        "#Refer: https://docs.scipy.org/doc/scipy/reference/sparse.html\n",
        "\n",
        "\n",
        "print(X_BoW.data.nbytes) # Refer: https://stackoverflow.com/questions/43681279/why-is-scipy-sparse-matrix-memory-usage-indifferent-of-the-number-of-elements-in\n",
        "\n",
        "# Convert X_BoW to dense\n",
        "# Ref: https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.todense.html#scipy.sparse.csr_matrix.todense\n",
        "X_BoW_Dense = X_BoW.todense();\n",
        "print(X_BoW_Dense.data.nbytes)\n",
        "\n",
        "print(X_BoW.shape)\n",
        "print(X_BoW_Dense.shape)\n",
        "# Always use sparse-matrix in these situations"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82968\n",
            "3626400\n",
            "(100, 4533)\n",
            "(100, 4533)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R_zmddCtMID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6dbc868-f93e-4894-e8fd-6aa479bd1ab1"
      },
      "source": [
        "print(X_BoW[0,:])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 4072)\t2\n",
            "  (0, 2713)\t6\n",
            "  (0, 361)\t1\n",
            "  (0, 4082)\t1\n",
            "  (0, 2510)\t1\n",
            "  (0, 3303)\t1\n",
            "  (0, 2197)\t1\n",
            "  (0, 1445)\t1\n",
            "  (0, 419)\t1\n",
            "  (0, 80)\t1\n",
            "  (0, 2461)\t1\n",
            "  (0, 4064)\t2\n",
            "  (0, 510)\t1\n",
            "  (0, 819)\t1\n",
            "  (0, 4061)\t3\n",
            "  (0, 4086)\t2\n",
            "  (0, 1512)\t1\n",
            "  (0, 944)\t1\n",
            "  (0, 3035)\t1\n",
            "  (0, 3616)\t1\n",
            "  (0, 3028)\t1\n",
            "  (0, 2442)\t3\n",
            "  (0, 943)\t1\n",
            "  (0, 3170)\t1\n",
            "  (0, 868)\t1\n",
            "  :\t:\n",
            "  (0, 2619)\t1\n",
            "  (0, 4167)\t1\n",
            "  (0, 1714)\t1\n",
            "  (0, 2677)\t1\n",
            "  (0, 2028)\t1\n",
            "  (0, 1361)\t1\n",
            "  (0, 1592)\t1\n",
            "  (0, 2400)\t1\n",
            "  (0, 1375)\t1\n",
            "  (0, 2455)\t1\n",
            "  (0, 226)\t1\n",
            "  (0, 954)\t1\n",
            "  (0, 2505)\t2\n",
            "  (0, 1797)\t1\n",
            "  (0, 2519)\t1\n",
            "  (0, 341)\t1\n",
            "  (0, 4381)\t1\n",
            "  (0, 971)\t1\n",
            "  (0, 2057)\t1\n",
            "  (0, 4436)\t1\n",
            "  (0, 1892)\t1\n",
            "  (0, 1472)\t1\n",
            "  (0, 1184)\t1\n",
            "  (0, 629)\t1\n",
            "  (0, 2503)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psSkrgLsts56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10a436d4-3f4e-433f-8e6f-107d59f6c188"
      },
      "source": [
        "print(X_BoW[0,818])\n",
        "print(X_BoW[0,817])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQoWQhgltXl_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fab0358c-ce93-41fe-d5ac-008e32ed541e"
      },
      "source": [
        "print(X_BoW_Dense[0,:])\n",
        "print(X_BoW_Dense[0,818])\n",
        "print(X_BoW_Dense[0,817])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 ... 0 0 0]]\n",
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtkAMxGAljIq"
      },
      "source": [
        "#<font color = 'green'><b>TD-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDB1gor2t9yh"
      },
      "source": [
        "# Google: \"TF-IDF SkLearn\" ---> https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2))\n",
        "X_tfidf = vectorizer.fit_transform(raw_data)\n",
        "\n",
        "#print(vectorizer.get_feature_names())"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nLmIgy2vNjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d70afc22-232e-4767-a486-6967bff1557f"
      },
      "source": [
        "print(type(X_tfidf))\n",
        "print(X_tfidf.shape)\n",
        "print(X_tfidf.data.nbytes) # Refer: https://stackoverflow.com/questions/43681279/why-is-scipy-sparse-matrix-memory-usage-indifferent-of-the-number-of-elements-in\n",
        "\n",
        "X_tfidf_dense = X_tfidf.todense()\n",
        "print(type(X_tfidf_dense))\n",
        "print(X_tfidf_dense.shape)\n",
        "print(X_tfidf_dense.data.nbytes)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse.csr.csr_matrix'>\n",
            "(100, 14902)\n",
            "156768\n",
            "<class 'numpy.matrix'>\n",
            "(100, 14902)\n",
            "11921600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9Eqvyl5lke7"
      },
      "source": [
        "#<font color = 'green'><b>Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGNnb80o9YCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3f06651-deed-4172-8196-bc2996764496"
      },
      "source": [
        "# Gensim\n",
        "# Refer: https://machinelearningmastery.com/develop-word-embeddings-python-gensim/\n",
        "\n",
        "# Download pretrained  vectors\n",
        "# https://www.quora.com/How-can-I-download-the-Google-news-word2vec-pretrained-model-from-a-Ubuntu-terminal\n",
        "! wget https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
        "! gunzip GoogleNews-vectors-negative300.bin.gz\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-03 12:59:19--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 54.231.196.128\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|54.231.196.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2022-05-03 12:59:19 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pMqN_CZD9M0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ef61282-2aa3-4f46-bd91-20f677afa085"
      },
      "source": [
        "! ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aclImdb  aclImdb_v1.tar.gz  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2OpgG5tDLiR"
      },
      "source": [
        "# takes time as the model is large to laod into RAM\n",
        "# RAM consumption also shoots up. Kernel could restart and give you a larger RAM isnatnce like 25GB RAM\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "filename = 'GoogleNews-vectors-negative300.bin'\n",
        "model = KeyedVectors.load_word2vec_format(filename, binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1uuxybcDWKP"
      },
      "source": [
        "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPPAs4oGFaWo"
      },
      "source": [
        "v = model['queen'];\n",
        "print(type(v))\n",
        "print(v.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKycP4IrlnCg"
      },
      "source": [
        "#<font color = 'green'><b>BERT\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- BERT vs Word2Vec\n",
        "- BERT: Contextual encodings"
      ],
      "metadata": {
        "id": "zquTrr15Oebq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgdeT6KK7_Mv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b54d3558-bbb1-4607-b27a-5b6f382ae693"
      },
      "source": [
        "# There are many ways to obatin BERT encodings. We are using one of the \n",
        "# most simple+popular approaches\n",
        "# use GPU based instance: Runtime---> Change Runtime --> GPU\n",
        "\n",
        "# Change to TensorFlow Version 1.x \n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o10-H_0K8WBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "372fcdf7-933d-4f18-83f7-a2775280c03b"
      },
      "source": [
        "#https://github.com/hanxiao/bert-as-service\n",
        "\n",
        "# https://github.com/hanxiao/bert-as-service/issues/380\n",
        "# Install BERT-SERVING client and Server\n",
        "!pip install bert-serving-client\n",
        "!pip install -U bert-serving-server[http]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert-serving-client\n",
            "  Downloading bert_serving_client-1.10.0-py2.py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bert-serving-client) (1.21.6)\n",
            "Requirement already satisfied: pyzmq>=17.1.0 in /usr/local/lib/python3.7/dist-packages (from bert-serving-client) (22.3.0)\n",
            "Installing collected packages: bert-serving-client\n",
            "Successfully installed bert-serving-client-1.10.0\n",
            "Collecting bert-serving-server[http]\n",
            "  Downloading bert_serving_server-1.10.0-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 242 kB/s \n",
            "\u001b[?25hCollecting GPUtil>=1.3.0\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from bert-serving-server[http]) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from bert-serving-server[http]) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bert-serving-server[http]) (1.21.6)\n",
            "Requirement already satisfied: pyzmq>=17.1.0 in /usr/local/lib/python3.7/dist-packages (from bert-serving-server[http]) (22.3.0)\n",
            "Requirement already satisfied: bert-serving-client in /usr/local/lib/python3.7/dist-packages (from bert-serving-server[http]) (1.10.0)\n",
            "Collecting flask-json\n",
            "  Downloading Flask_JSON-0.3.4-py3-none-any.whl (9.0 kB)\n",
            "Collecting flask-cors\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from bert-serving-server[http]) (1.1.4)\n",
            "Collecting flask-compress\n",
            "  Downloading Flask_Compress-1.12-py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask->bert-serving-server[http]) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->bert-serving-server[http]) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->bert-serving-server[http]) (1.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->bert-serving-server[http]) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask->bert-serving-server[http]) (2.0.1)\n",
            "Collecting brotli\n",
            "  Downloading Brotli-1.0.9-cp37-cp37m-manylinux1_x86_64.whl (357 kB)\n",
            "\u001b[K     |████████████████████████████████| 357 kB 11.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=9e38d59d974289fbd25ce81322f5a854d00e47f8b08b13e677479ebca94878a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil, brotli, flask-json, flask-cors, flask-compress, bert-serving-server\n",
            "Successfully installed GPUtil-1.4.0 bert-serving-server-1.10.0 brotli-1.0.9 flask-compress-1.12 flask-cors-3.0.10 flask-json-0.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTHBbZdi8bxV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f0c5d98-14d4-4fa7-ec74-86fe270f667b"
      },
      "source": [
        "# dowload pretrained models\n",
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
        "!unzip uncased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-03 17:53:35--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.129.128, 108.177.112.128, 172.253.119.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.129.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 407727028 (389M) [application/zip]\n",
            "Saving to: ‘uncased_L-12_H-768_A-12.zip’\n",
            "\n",
            "uncased_L-12_H-768_ 100%[===================>] 388.84M   167MB/s    in 2.3s    \n",
            "\n",
            "2022-05-03 17:53:38 (167 MB/s) - ‘uncased_L-12_H-768_A-12.zip’ saved [407727028/407727028]\n",
            "\n",
            "Archive:  uncased_L-12_H-768_A-12.zip\n",
            "   creating: uncased_L-12_H-768_A-12/\n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNJehrNH8fmJ"
      },
      "source": [
        "# Start BERT_SERVER on the current computer\n",
        "!nohup bert-serving-start -model_dir=./uncased_L-12_H-768_A-12 > out.file 2>&1 &"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hgCh2j28pfl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "60d88d9a-c465-4afb-f3e0-ae728fbb2e10"
      },
      "source": [
        "# Use bert-client from python\n",
        "# Takes time to execute as it uses GPU\n",
        "from bert_serving.client import BertClient\n",
        "bc = BertClient()\n",
        "print (bc.encode(['First do it', 'then do it right', 'then do it better'])) # list of setences"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a1498c311190>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Takes time to execute as it uses GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbert_serving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'First do it'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'then do it right'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'then do it better'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# list of setences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bert_serving/client/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ip, port, port_out, output_fmt, show_server_config, identity, check_version, check_length, check_token_info, ignore_all_checks, timeout)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_all_checks\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcheck_version\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mshow_server_config\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcheck_length\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcheck_token_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0ms_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck_version\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ms_status\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'server_version'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'client_version'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bert_serving/client/__init__.py\u001b[0m in \u001b[0;36marg_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceiver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRCVTIMEO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_e\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 t_e = TimeoutError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bert_serving/client/__init__.py\u001b[0m in \u001b[0;36mserver_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \"\"\"\n\u001b[1;32m    231\u001b[0m         \u001b[0mreq_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'SHOW_CONFIG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjsonapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bert_serving/client/__init__.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, wait_for_req_id)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;31m# receive a response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceiver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m                 \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0many\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mmight\u001b[0m \u001b[0mfail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRCVMORE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpse3FmnA21x"
      },
      "source": [
        "v = bc.encode([raw_data[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgPz2p6_Bi0B"
      },
      "source": [
        "print(type(v))\n",
        "print(v.shape)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}